{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Main.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c2a263d20c7942af9e1d80d6e9be77fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a6a86741f28c49ebba976a29a613e265","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6f8d7f7d45ec472db932101fc0fc34c5","IPY_MODEL_29dfe8f5242145e79fe1222e442509bf","IPY_MODEL_c3559b851cfb41e5aefebe389c2c82f3"]}},"a6a86741f28c49ebba976a29a613e265":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6f8d7f7d45ec472db932101fc0fc34c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1fb1cae14bf949e78e03325008ba02fb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_49f53c088b0a4729bb2bcd6edbbe88a6"}},"29dfe8f5242145e79fe1222e442509bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e0b2fa0d25f840899db3a2526c6bbeca","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":170498071,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":170498071,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa2862155bf54bdeb472be3c2d993d23"}},"c3559b851cfb41e5aefebe389c2c82f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_29a566e5e7174f8ebcad03b80ff9553f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170499072/? [00:06&lt;00:00, 30283422.47it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dcd17d73f1a94babb8f15ba6e2610b10"}},"1fb1cae14bf949e78e03325008ba02fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"49f53c088b0a4729bb2bcd6edbbe88a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0b2fa0d25f840899db3a2526c6bbeca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"aa2862155bf54bdeb472be3c2d993d23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"29a566e5e7174f8ebcad03b80ff9553f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dcd17d73f1a94babb8f15ba6e2610b10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PeA1JLRfcOjC","executionInfo":{"status":"ok","timestamp":1638027601332,"user_tz":-330,"elapsed":11008,"user":{"displayName":"yuva raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdkdz2OGyiDD4DcDpck-HlvbnOdc5c6SvCfekVsw=s64","userId":"17299640264913684447"}},"outputId":"7c950cf9-77c0-4ed9-f0d9-ee5d6ff486ab"},"source":["!pip install --upgrade albumentations"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n","Collecting albumentations\n","  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n","\u001b[?25l\r\u001b[K     |███▏                            | 10 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 20 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 30 kB 18.2 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 40 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 51 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 61 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 71 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 81 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 92 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102 kB 13.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n","Collecting qudida>=0.0.4\n","  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n","Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.18.3)\n","Collecting opencv-python-headless>=4.1.1\n","  Downloading opencv_python_headless-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.6 MB)\n","\u001b[K     |████████████████████████████████| 47.6 MB 2.2 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n","Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (1.0.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (3.10.0.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (3.0.6)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n","Installing collected packages: opencv-python-headless, qudida, albumentations\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 0.1.12\n","    Uninstalling albumentations-0.1.12:\n","      Successfully uninstalled albumentations-0.1.12\n","Successfully installed albumentations-1.1.0 opencv-python-headless-4.5.4.60 qudida-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"xUdw-TAUce65","executionInfo":{"status":"ok","timestamp":1638027680384,"user_tz":-330,"elapsed":684,"user":{"displayName":"yuva raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdkdz2OGyiDD4DcDpck-HlvbnOdc5c6SvCfekVsw=s64","userId":"17299640264913684447"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","import torch \n","from torchvision import datasets, transforms\n","from torchsummary import summary"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"il2YyqVDDsdN","executionInfo":{"status":"ok","timestamp":1638027769918,"user_tz":-330,"elapsed":27967,"user":{"displayName":"yuva raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdkdz2OGyiDD4DcDpck-HlvbnOdc5c6SvCfekVsw=s64","userId":"17299640264913684447"}},"outputId":"6c551340-2443-4515-8ee3-62fee1fb99c4"},"source":["from albumentations.pytorch import ToTensorV2\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","BASE_DIR='/content/drive/My Drive/Session_8'\n","%cd $BASE_DIR"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/Session_8\n"]}]},{"cell_type":"code","metadata":{"id":"u4o7myIPkr7c","executionInfo":{"status":"ok","timestamp":1638029864825,"user_tz":-330,"elapsed":1748,"user":{"displayName":"yuva raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdkdz2OGyiDD4DcDpck-HlvbnOdc5c6SvCfekVsw=s64","userId":"17299640264913684447"}}},"source":["from models import resnet\n","from utils import gradcam\n","from dataloaders.CIFAR10 import download_data, get_train_test_loaders,LoadDataset\n","from main import fit_model"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbKMt2y0kn_h","executionInfo":{"status":"ok","timestamp":1638027940887,"user_tz":-330,"elapsed":533,"user":{"displayName":"yuva raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdkdz2OGyiDD4DcDpck-HlvbnOdc5c6SvCfekVsw=s64","userId":"17299640264913684447"}},"outputId":"525fab4c-af4a-42f3-ff69-698cf0319e8c"},"source":["import importlib\n","importlib.reload(gradcam)\n","# importlib.reload(resnet)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'utils.gradcam' from '/content/drive/My Drive/Session_8/utils/gradcam.py'>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"CyiFUvkodcLY","executionInfo":{"status":"ok","timestamp":1638028206624,"user_tz":-330,"elapsed":661,"user":{"displayName":"yuva raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdkdz2OGyiDD4DcDpck-HlvbnOdc5c6SvCfekVsw=s64","userId":"17299640264913684447"}}},"source":["# Apply these transforms while training:\n","# RandomCrop(32, padding=4)\n","# CutOut(16x16)\n","# Rotate(±5°)\n","\n","train_transform = A.Compose({\n","  A.Rotate (limit=5, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n","  A.Sequential([A.CropAndPad(px=4, keep_size=False), #padding of 2, keep_size=True by default\n","                A.RandomCrop(32,32)]),\n","  A.CoarseDropout(1, 16, 16, 1, 16, 16,fill_value=0.473363, mask_fill_value=None),\n","  A.Normalize((0.49139968, 0.48215841, 0.44653091), (0.24703223, 0.24348513, 0.26158784)),\n","})\n","\n","test_transform = A.Compose({\n","  A.Normalize((0.49139968, 0.48215841, 0.44653091), (0.24703223, 0.24348513, 0.26158784))\n","})"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZoU1mcfdk66o","executionInfo":{"status":"ok","timestamp":1638028210810,"user_tz":-330,"elapsed":636,"user":{"displayName":"yuva raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdkdz2OGyiDD4DcDpck-HlvbnOdc5c6SvCfekVsw=s64","userId":"17299640264913684447"}},"outputId":"d8555452-771b-4263-c4bd-928025267c38"},"source":["cuda = torch.cuda.is_available()\n","print(\"CUDA Available:\", cuda)\n","SEED = 1\n","# For reproducibility\n","torch.manual_seed(SEED)\n","\n","if cuda:\n","    torch.cuda.manual_seed(SEED)\n","    BATCH_SIZE=64\n","else:\n","    BATCH_SIZE=32"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA Available: True\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101,"referenced_widgets":["c2a263d20c7942af9e1d80d6e9be77fe","a6a86741f28c49ebba976a29a613e265","6f8d7f7d45ec472db932101fc0fc34c5","29dfe8f5242145e79fe1222e442509bf","c3559b851cfb41e5aefebe389c2c82f3","1fb1cae14bf949e78e03325008ba02fb","49f53c088b0a4729bb2bcd6edbbe88a6","e0b2fa0d25f840899db3a2526c6bbeca","aa2862155bf54bdeb472be3c2d993d23","29a566e5e7174f8ebcad03b80ff9553f","dcd17d73f1a94babb8f15ba6e2610b10"]},"id":"gK0zNG9SHvSd","executionInfo":{"status":"ok","timestamp":1638028804419,"user_tz":-330,"elapsed":13981,"user":{"displayName":"yuva raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdkdz2OGyiDD4DcDpck-HlvbnOdc5c6SvCfekVsw=s64","userId":"17299640264913684447"}},"outputId":"817ee377-c8ab-4e5b-a2ac-9bb6b47d6e75"},"source":["import cv2\n","import torchvision\n","import torch\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","\n","# Albumentations for augmentations\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","torch.manual_seed(2)\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","cv2.setNumThreads(0)\n","cv2.ocl.setUseOpenCL(False)\n","\n","class Cifar10SearchDataset(torchvision.datasets.CIFAR10):\n","    def __init__(self, root=\"~/data/cifar10\", train=True, download=True, transform=None):\n","        super().__init__(root=root, train=train, download=download, transform=transform)\n","\n","    def __getitem__(self, index):\n","        image, label = self.data[index], self.targets[index]\n","\n","        if self.transform is not None:\n","            transformed = self.transform(image=image)\n","            image = transformed[\"image\"]\n","\n","        return image, label\n","\n","\n","train_transforms = A.Compose(\n","    [\n","        A.HorizontalFlip(p=0.5),\n","        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.5),\n","        A.CoarseDropout(max_holes = 1, max_height=16, max_width=16, min_holes = 1, min_height=16, min_width=16,\n","                        fill_value=0.4734),\n","        A.Normalize(\n","            mean = (0.4914, 0.4822, 0.4465),\n","            std = (0.2470, 0.2435, 0.2616),\n","            p =1.0\n","        ),\n","        ToTensorV2()\n","    ],\n","    p=1.0\n",")\n","\n","test_transforms = A.Compose(\n","    [\n","        A.Normalize(\n","            mean = (0.4914, 0.4822, 0.4465),\n","            std = (0.2470, 0.2435, 0.2616),\n","            p =1.0\n","        ),\n","        ToTensorV2()\n","    ]\n",")\n","\n","class args():\n","    def __init__(self,device = 'cpu' ,use_cuda = False) -> None:\n","        self.batch_size = 128\n","        self.device = device\n","        self.use_cuda = use_cuda\n","        self.kwargs = {'num_workers': 2, 'pin_memory': True} if self.use_cuda else {}\n","\n","trainset = Cifar10SearchDataset(root='./data', train=True,\n","                                        download=True, transform=train_transforms)\n","                                        \n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=args().batch_size,\n","                                          shuffle=True, **args(use_cuda=True).kwargs)\n","\n","\n","testset = Cifar10SearchDataset(root='./data', train=False,\n","                                       download=True, transform=test_transforms)\n","\n","testloader = torch.utils.data.DataLoader(testset, batch_size=args().batch_size,\n","                                         shuffle=False, **args(use_cuda=True).kwargs)\n","\n","##\n","# functions to show an image\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","\n","\n","# # get some random training images\n","# dataiter = iter(trainloader)\n","# images, labels = dataiter.next()\n","\n","# # show images\n","# imshow(torchvision.utils.make_grid(images))\n","# # print labels\n","# print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n","\n","def get_statistics(dataset):\n","\n","    \"\"\"\n","    input = dataset should be a of type torchvision.datasets calculate statistics of training data only \n","    Calculated stats are->\n","    torch.Size([3, 32, 32, 50000])\n","    Mean =  tensor([0.4914, 0.4822, 0.4465])\n","    Standard deviation =  tensor([0.2470, 0.2435, 0.2616])\n","    \n","    \"\"\"\n","    imgs = torch.stack([img_t for img_t,_ in dataset],dim = 3)\n","    print(imgs.shape)\n","\n","    mean_calc = imgs.view(3,-1).mean(dim = 1)\n","    std_dev_calc = imgs.view(3,-1).std(dim = 1)\n","\n","    print('Mean = ',mean_calc)\n","    print('Standard deviation = ',std_dev_calc)\n","\n","    return mean_calc,std_dev_calc"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2a263d20c7942af9e1d80d6e9be77fe","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","metadata":{"id":"rDLrhBB_3PR7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638030158174,"user_tz":-330,"elapsed":728,"user":{"displayName":"yuva raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdkdz2OGyiDD4DcDpck-HlvbnOdc5c6SvCfekVsw=s64","userId":"17299640264913684447"}},"outputId":"855666c0-46be-4a27-d66a-ade64fa31b52"},"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","print(device)"],"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"niTelJJClzt-","executionInfo":{"status":"ok","timestamp":1638028822279,"user_tz":-330,"elapsed":9368,"user":{"displayName":"yuva raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdkdz2OGyiDD4DcDpck-HlvbnOdc5c6SvCfekVsw=s64","userId":"17299640264913684447"}},"outputId":"dc373b7e-085f-484b-a738-1b9ff59c3eb5"},"source":["net_18 = resnet.ResNet18().to(device)\n","summary(net_18, input_size=(3, 32, 32))"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,728\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","            Conv2d-3           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-4           [-1, 64, 32, 32]             128\n","            Conv2d-5           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-6           [-1, 64, 32, 32]             128\n","        BasicBlock-7           [-1, 64, 32, 32]               0\n","            Conv2d-8           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-9           [-1, 64, 32, 32]             128\n","           Conv2d-10           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-11           [-1, 64, 32, 32]             128\n","       BasicBlock-12           [-1, 64, 32, 32]               0\n","           Conv2d-13          [-1, 128, 16, 16]          73,728\n","      BatchNorm2d-14          [-1, 128, 16, 16]             256\n","           Conv2d-15          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-16          [-1, 128, 16, 16]             256\n","           Conv2d-17          [-1, 128, 16, 16]           8,192\n","      BatchNorm2d-18          [-1, 128, 16, 16]             256\n","       BasicBlock-19          [-1, 128, 16, 16]               0\n","           Conv2d-20          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-21          [-1, 128, 16, 16]             256\n","           Conv2d-22          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-23          [-1, 128, 16, 16]             256\n","       BasicBlock-24          [-1, 128, 16, 16]               0\n","           Conv2d-25            [-1, 256, 8, 8]         294,912\n","      BatchNorm2d-26            [-1, 256, 8, 8]             512\n","           Conv2d-27            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-28            [-1, 256, 8, 8]             512\n","           Conv2d-29            [-1, 256, 8, 8]          32,768\n","      BatchNorm2d-30            [-1, 256, 8, 8]             512\n","       BasicBlock-31            [-1, 256, 8, 8]               0\n","           Conv2d-32            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-33            [-1, 256, 8, 8]             512\n","           Conv2d-34            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-35            [-1, 256, 8, 8]             512\n","       BasicBlock-36            [-1, 256, 8, 8]               0\n","           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n","      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n","           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n","           Conv2d-41            [-1, 512, 4, 4]         131,072\n","      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n","       BasicBlock-43            [-1, 512, 4, 4]               0\n","           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n","           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n","       BasicBlock-48            [-1, 512, 4, 4]               0\n","           Linear-49                   [-1, 10]           5,130\n","================================================================\n","Total params: 11,173,962\n","Trainable params: 11,173,962\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 11.25\n","Params size (MB): 42.63\n","Estimated Total Size (MB): 53.89\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","metadata":{"id":"9BpxC3uKT2lB"},"source":["optimizer = torch.optim.SGD(net_18.parameters(), lr=0.01, momentum=0.9)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer,mode='min', patience=8, verbose=True)\n","\n","net_18, history_18 = fit_model(\n","    net=net_18,\n","    train_loader=trainloader, test_loader=testloader,\n","    scheduler=scheduler, \n","    optimizer=optimizer, device=device, NUM_EPOCHS=40\n",")"],"execution_count":null,"outputs":[]}]}